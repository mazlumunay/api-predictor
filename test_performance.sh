#!/bin/bash

echo "ğŸš€ Performance Testing Script - OpenSesame Requirements"
echo "Target: Median <1000ms, P95 <3000ms"
echo "======================================"

BASE_URL="http://localhost:8000"
SPEC_URL="https://petstore.swagger.io/v2/swagger.json"

# Check if service is running
echo "ğŸ” Checking service health..."
if ! curl -s "$BASE_URL/health" > /dev/null 2>&1; then
    echo "âŒ Service not running. Please start with: docker-compose up -d"
    exit 1
fi

echo "âœ… Service is running"

# Warm up cache
echo -e "\nğŸ”¥ Warming up cache..."
curl -s -X POST $BASE_URL/predict \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "warmup",
    "events": [{"ts": "2025-07-14T14:00:00Z", "endpoint": "GET /pet/1", "params": {}}],
    "spec_url": "'$SPEC_URL'",
    "k": 3
  }' > /dev/null

echo "âœ… Cache warmed up"

# Performance test with optimizations
times=()
cached_times=()

echo -e "\nâš¡ Running performance tests..."
echo "Testing 20 requests (mix of cache miss and cache hit scenarios)"

for i in {1..20}; do
  echo -n "Request $i: "
  
  # Vary the user_id to test different scenarios
  if [ $((i % 4)) -eq 0 ]; then
    # Every 4th request uses same user (cache hit scenario)
    user_id="cache-user"
    scenario="cached"
  else
    # Other requests use unique user (cache miss scenario)
    user_id="perf-test-$i"
    scenario="fresh"
  fi
  
  start_time=$(date +%s%N)
  response=$(curl -s -X POST $BASE_URL/predict \
    -H "Content-Type: application/json" \
    -d '{
      "user_id": "'$user_id'",
      "events": [
        {"ts": "2025-07-14T14:00:00Z", "endpoint": "GET /pet/findByStatus", "params": {"status": "available"}},
        {"ts": "2025-07-14T14:01:00Z", "endpoint": "GET /pet/'$((i+100))'", "params": {}}
      ],
      "spec_url": "'$SPEC_URL'",
      "k": 3
    }')
  end_time=$(date +%s%N)
  
  # Check if successful
  if echo "$response" | jq -e '.predictions' > /dev/null 2>&1; then
    processing_time=$(echo "$response" | jq -r '.processing_time_ms')
    total_time=$(( (end_time - start_time) / 1000000 ))
    is_cached=$(echo "$response" | jq -r '.cached // false')
    
    times+=($total_time)
    
    if [ "$is_cached" = "true" ] || [ "$scenario" = "cached" ]; then
      cached_times+=($total_time)
      echo "${processing_time}ms (total: ${total_time}ms) ğŸŸ¢ cached"
    else
      echo "${processing_time}ms (total: ${total_time}ms) ğŸ”µ fresh"
    fi
  else
    echo "FAILED âŒ"
  fi
  
  # Small delay to avoid overwhelming
  sleep 0.05
done

# Calculate statistics
if [ ${#times[@]} -gt 0 ]; then
  echo -e "\nğŸ“Š Performance Results:"
  
  # Overall statistics
  IFS=$'\n' sorted=($(sort -n <<<"${times[*]}"))
  n=${#sorted[@]}
  median=${sorted[$((n/2))]}
  p95=${sorted[$((n*95/100))]}
  min=${sorted[0]}
  max=${sorted[$((n-1))]}
  
  # Calculate average
  sum=0
  for time in "${times[@]}"; do
    sum=$((sum + time))
  done
  avg=$((sum / n))
  
  echo "  ğŸ“ˆ Overall Performance:"
  echo "    Min:     ${min}ms"
  echo "    Median:  ${median}ms (target: <1000ms) $([ $median -lt 1000 ] && echo "âœ…" || echo "âŒ")"
  echo "    Average: ${avg}ms"
  echo "    P95:     ${p95}ms (target: <3000ms) $([ $p95 -lt 3000 ] && echo "âœ…" || echo "âŒ")"
  echo "    Max:     ${max}ms"
  echo "    Success: ${#times[@]}/20 requests"
  
  # Cached request statistics
  if [ ${#cached_times[@]} -gt 0 ]; then
    IFS=$'\n' cached_sorted=($(sort -n <<<"${cached_times[*]}"))
    cached_n=${#cached_sorted[@]}
    cached_median=${cached_sorted[$((cached_n/2))]}
    cached_max=${cached_sorted[$((cached_n-1))]}
    
    echo -e "\n  ğŸŸ¢ Cached Request Performance:"
    echo "    Median:  ${cached_median}ms"
    echo "    Max:     ${cached_max}ms" 
    echo "    Count:   ${cached_n} requests"
  fi
  
  # Performance assessment
  echo -e "\nğŸ¯ Assessment:"
  
  if [ $median -lt 1000 ] && [ $p95 -lt 3000 ]; then
    echo "ğŸ‰ PERFORMANCE REQUIREMENTS MET!"
    echo "âœ… Median: ${median}ms < 1000ms target"
    echo "âœ… P95: ${p95}ms < 3000ms target"
    
    if [ ${#cached_times[@]} -gt 0 ] && [ $cached_median -lt 500 ]; then
      echo "ğŸš€ Excellent cache performance: ${cached_median}ms median for cached requests"
    fi
    
  elif [ $median -lt 1000 ]; then
    echo "âš ï¸  Median target met, but P95 needs improvement"
    echo "âœ… Median: ${median}ms < 1000ms target"
    echo "âŒ P95: ${p95}ms â‰¥ 3000ms target"
    echo "ğŸ’¡ Suggestion: Check for OpenAI API latency spikes"
    
  elif [ $p95 -lt 3000 ]; then
    echo "âš ï¸  P95 target met, but median needs improvement"
    echo "âŒ Median: ${median}ms â‰¥ 1000ms target"
    echo "âœ… P95: ${p95}ms < 3000ms target"
    echo "ğŸ’¡ Suggestion: Improve cache hit rate or optimize first-time requests"
    
  else:
    echo "âŒ Performance targets not met"
    echo "âŒ Median: ${median}ms â‰¥ 1000ms target"
    echo "âŒ P95: ${p95}ms â‰¥ 3000ms target"
    echo "ğŸ’¡ Optimization suggestions:"
    echo "   - Check OpenAI API key and quota"
    echo "   - Verify Redis is running and connected"
    echo "   - Monitor OpenAPI spec parsing times"
    echo "   - Consider reducing timeout values"
  fi
  
  # Improvement suggestions
  echo -e "\nğŸ’¡ Performance Optimization Tips:"
  
  if [ $median -gt 800 ]; then
    echo "  ğŸ”§ Consider enabling more aggressive caching"
    echo "  ğŸ”§ Reduce OpenAI context size for faster responses"
  fi
  
  if [ $p95 -gt 2000 ]; then
    echo "  ğŸ”§ Check for OpenAI API timeout issues"
    echo "  ğŸ”§ Implement request batching for similar queries"
  fi
  
  if [ ${#cached_times[@]} -eq 0 ]; then
    echo "  ğŸ”§ No cached requests detected - check cache implementation"
  fi
  
else
  echo "âŒ No successful requests - check service health"
  exit 1
fi

# Additional diagnostics
echo -e "\nğŸ” Diagnostic Information:"

# Check cache metrics
echo "ğŸ“Š Cache Performance:"
cache_metrics=$(curl -s $BASE_URL/metrics | jq '.last_10_minutes')
if [ "$cache_metrics" != "null" ]; then
  cache_hit_rate=$(echo "$cache_metrics" | jq -r '.cache_hit_rate // 0')
  cache_percentage=$(echo "$cache_hit_rate * 100" | bc -l 2>/dev/null || echo "0")
  echo "  Cache hit rate: ${cache_percentage}%"
else
  echo "  Cache metrics unavailable"
fi

# Check OpenAI status
echo "ğŸ¤– AI Layer Status:"
if grep -q "OpenAI client initialized successfully" <<< "$(docker-compose logs api-predictor 2>/dev/null)" 2>/dev/null; then
  echo "  âœ… OpenAI client initialized"
else
  echo "  âš ï¸  OpenAI client may not be initialized"
fi

if grep -q "insufficient_quota\|Incorrect API key" <<< "$(docker-compose logs api-predictor 2>/dev/null)" 2>/dev/null; then
  echo "  âŒ OpenAI API key issues detected"
else
  echo "  âœ… No OpenAI API errors in recent logs"
fi

# Check ML model status
echo "ğŸ§  ML Layer Status:"
if grep -q "ML model loaded successfully\|New model trained" <<< "$(docker-compose logs api-predictor 2>/dev/null)" 2>/dev/null; then
  echo "  âœ… ML model operational"
else
  echo "  âš ï¸  ML model status unclear"
fi

echo -e "\nğŸ“‹ Test Summary:"
echo "  Total requests: 20"
echo "  Successful: ${#times[@]}"
echo "  Failed: $((20 - ${#times[@]}))"
echo "  Cached responses: ${#cached_times[@]}"
echo "  Fresh responses: $((${#times[@]} - ${#cached_times[@]}))"

# Final recommendation
echo -e "\nğŸ¯ Final Recommendation:"
if [ $median -lt 1000 ] && [ $p95 -lt 3000 ]; then
  echo "ğŸ‰ Ready for OpenSesame submission!"
  echo "   Your implementation meets all performance requirements."
else
  echo "ğŸ”§ Apply optimizations and retest before submission."
  echo "   Focus on the suggestions above to meet performance targets."
fi

echo -e "\nâœ… Performance test completed!"